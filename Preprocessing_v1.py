from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np

df = pd.read_csv("Obfuscated-MalMem2022.csv", sep=',', encoding='utf-8')

for column in df.columns:
    if df[column].nunique() == 1:  # Find out whether the data is unique or not.
        print(f"All values {column} are identical")

# So we dont need printed values cuz they're already identical.
columns_to_drop = ['pslist.nprocs64bit', 'handles.nport', 'svcscan.interactive_process_services']
df.drop(columns=columns_to_drop, inplace=True)

# Forward filling missing values and dropping duplicates.
df.ffill()
df.drop_duplicates(inplace=True)


def find_category(column):
    if "-" in column:
        category = column.split("-")[0]
        return category
    else:
        return column


# Printing Categories
df["Category"] = df["Category"].apply(find_category)

# Data Type Conversion
df["Class"] = df["Class"].astype("category")

# Handling Categorical Data
df = pd.get_dummies(df, columns=["Class"], drop_first=True)

# Separate features and target
y = df["Class_Malware"]
X = df.drop(columns=["Category", "Class_Malware"])


# Burayı anlamadım açıkçası----------------------------
pca = PCA()
feature_scaled = StandardScaler().fit_transform(X)
feature_pca = pca.fit_transform(feature_scaled)
explained_variance_ratio = pca.explained_variance_ratio_
cumulative_variance_ratio = np.cumsum(explained_variance_ratio)

plt.plot(cumulative_variance_ratio)
plt.xlabel('Number of Principal Components')
plt.ylabel('Cumulative Explained Variance Ratio')
plt.grid(True)
plt.show()
#------------------------------------------------------


from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA
lda = LDA(n_components=1)
X_lda = lda.fit_transform(feature_scaled, y)

from sklearn.manifold import TSNE

# Feature extraction using t-SNE
tsne = TSNE(n_components=2, perplexity=30, n_iter=300)
X_tsne = tsne.fit_transform(feature_scaled)


# Create subplots for side-by-side comparison
fig, axes = plt.subplots(1, 3, figsize=(15, 5))

# Plot PCA
axes[0].scatter(feature_pca[y == 0, 0], feature_pca[y == 0, 1], label="Benign", color="blue", alpha=0.5)
axes[0].scatter(feature_pca[y == 1, 0], feature_pca[y == 1, 1], label="Malicious", color="red", alpha=0.5)
axes[0].set_title("PCA")
axes[0].legend()

# Plot t-SNE
axes[1].scatter(X_tsne[y == 0, 0], X_tsne[y == 0, 1], label="Benign", color="blue", alpha=0.5)
axes[1].scatter(X_tsne[y == 1, 0], X_tsne[y == 1, 1], label="Malicious", color="red", alpha=0.5)
axes[1].set_title("t-SNE")
axes[1].legend()

# Plot LDA
axes[2].scatter(X_lda[y == 0, 0], X_lda[y == 0, 0], label="Benign", color="blue", alpha=0.5)
axes[2].scatter(X_lda[y == 1, 0], X_lda[y == 1, 0], label="Malicious", color="red", alpha=0.5)
axes[2].set_title("LDA")
axes[2].legend()

plt.show()


from sklearn.model_selection import train_test_split


X_part1, X_part2, y_part1, y_part2 = train_test_split(
    X, y, test_size=0.25, stratify=y, random_state=7)

num_malware = min(y_part1.sum(), y_part2.sum())
num_benign = min((~y_part1).sum(), (~y_part2).sum())

X_part1_malware = X_part1[y_part1 == 1].sample(num_malware)
X_part1_benign = X_part1[y_part1 == 0].sample(num_benign)

X_part2_malware = X_part2[y_part2 == 1].sample(num_malware)
X_part2_benign = X_part2[y_part2 == 0].sample(num_benign)

X_part1_combined = pd.concat([X_part1_malware, X_part1_benign], axis=0)
X_part1_combined.to_csv("X_part1_combined.csv", index=False)

X_part2_combined = pd.concat([X_part2_malware, X_part2_benign], axis=0)
X_part2_combined.to_csv("X_part2_combined.csv", index=False)