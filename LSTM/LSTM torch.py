import sklearn.metrics
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np

df = pd.read_csv("Obfuscated-MalMem2022.csv", sep=',', encoding='utf-8')

for column in df.columns:
    if df[column].nunique() == 1:  # Find out whether the data is unique or not.
        print(f"All values {column} are identical")

# So we dont need printed values cuz they're already identical.
columns_to_drop = ['pslist.nprocs64bit', 'handles.nport', 'svcscan.interactive_process_services']
df.drop(columns=columns_to_drop, inplace=True)

# Forward filling missing values and dropping duplicates.
df.ffill()
df.drop_duplicates(inplace=True)


def find_category(column):
    if "-" in column:
        category = column.split("-")[0]
        return category
    else:
        return column


# Printing Categories
df["Category"] = df["Category"].apply(find_category)
print(df["Category"].value_counts())

# Data Type Conversion
df["Class"] = df["Class"].astype("category")

# Handling Categorical Data
df = pd.get_dummies(df, columns=["Class"], drop_first=True)

# Separate features and target
y = df["Class_Malware"]
X = df.drop(columns=["Category", "Class_Malware"])

# PCA Implementation
pca = PCA()
feature_scaled = StandardScaler().fit_transform(X)
feature_pca = pca.fit_transform(feature_scaled)
explained_variance_ratio = pca.explained_variance_ratio_
cumulative_variance_ratio = np.cumsum(explained_variance_ratio)

plt.plot(cumulative_variance_ratio)
plt.xlabel('Number of Principal Components')
plt.ylabel('Cumulative Explained Variance Ratio')
plt.grid(True)
plt.show()
# ------------------------------------------------------

from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA

lda = LDA(n_components=1)
X_lda = lda.fit_transform(feature_scaled, y)

from sklearn.manifold import TSNE

# Feature extraction using t-SNE
# tsne = TSNE(n_components=2, perplexity=30, n_iter=300)
# X_tsne = tsne.fit_transform(feature_scaled)

# Create subplots for side-by-side comparison
fig, axes = plt.subplots(1, 3, figsize=(15, 5))

# Plot PCA
axes[0].scatter(feature_pca[y == 0, 0], feature_pca[y == 0, 1], label="Benign", color="blue", alpha=0.5)
axes[0].scatter(feature_pca[y == 1, 0], feature_pca[y == 1, 1], label="Malicious", color="red", alpha=0.5)
axes[0].set_title("PCA")
axes[0].legend()

# Plot t-SNE
# axes[1].scatter(X_tsne[y == 0, 0], X_tsne[y == 0, 1], label="Benign", color="blue", alpha=0.5)
# axes[1].scatter(X_tsne[y == 1, 0], X_tsne[y == 1, 1], label="Malicious", color="red", alpha=0.5)
# axes[1].set_title("t-SNE")
# axes[1].legend()

# Plot LDA
axes[2].scatter(X_lda[y == 0, 0], X_lda[y == 0, 0], label="Benign", color="blue", alpha=0.5)
axes[2].scatter(X_lda[y == 1, 0], X_lda[y == 1, 0], label="Malicious", color="red", alpha=0.5)
axes[2].set_title("LDA")
axes[2].legend()

plt.show()


# -----------------------------------------------------------------------------------------
# Alt kısım implementasyon
# -----------------------------------------------------------------------------------------

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import TensorDataset, DataLoader
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, auc, classification_report, confusion_matrix
import matplotlib.pyplot as plt

X_part1, X_part2, y_part1, y_part2 = train_test_split(X, y, test_size=0.50, stratify=y, random_state=7)

num_malware = min(y_part1.sum(), y_part2.sum())
num_benign = min((~y_part1).sum(), (~y_part2).sum())

X_part1_malware = X_part1[y_part1 == 1].sample(num_malware)
X_part1_benign = X_part1[y_part1 == 0].sample(num_benign)

X_part2_malware = X_part2[y_part2 == 1].sample(num_malware)
X_part2_benign = X_part2[y_part2 == 0].sample(num_benign)

y_part1_malware = y_part1[X_part1[y_part1 == 1].sample(num_malware).index]
y_part1_benign = y_part1[X_part1[y_part1 == 0].sample(num_benign).index]

y_part2_malware = y_part2[X_part2[y_part2 == 1].sample(num_malware).index]
y_part2_benign = y_part2[X_part2[y_part2 == 0].sample(num_benign).index]

X_part1_combined = pd.concat([X_part1_malware, X_part1_benign], axis=0)
X_part1_combined.to_csv("X_part1_combined.csv", index=False)

X_part2_combined = pd.concat([X_part2_malware, X_part2_benign], axis=0)
X_part2_combined.to_csv("X_part2_combined.csv", index=False)

y_part1_combined = pd.concat([y_part1_malware, y_part1_benign], axis=0)
y_part1_combined.to_csv("y_part1_combined.csv", index=False)

y_part2_combined = pd.concat([y_part2_malware, y_part2_benign], axis=0)
y_part2_combined.to_csv("y_part2_combined.csv", index=False)

X_train_tensor = torch.from_numpy(X_part1_combined.values).float()
y_train_tensor = torch.from_numpy(y_part1_combined.values).long()
X_test_tensor = torch.from_numpy(X_part2_combined.values).float()
y_test_tensor = torch.from_numpy(y_part2_combined.values).long()

# Assume X and y are your data and labels, replace them accordingly
# X and y should be torch tensors

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train_tensor)
X_test_scaled = scaler.transform(X_test_tensor)

X_train_reshaped = torch.tensor(X_train_scaled).unsqueeze(1).float()
X_test_reshaped = torch.tensor(X_test_scaled).unsqueeze(1).float()

y_train = y_train_tensor.float()
y_test = y_test_tensor.float()


# Define the LSTM model
class LSTMModel(nn.Module):
    def __init__(self, input_size, hidden_size, output_size):
        super(LSTMModel, self).__init__()
        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, batch_first=True)
        self.batch_norm = nn.BatchNorm1d(hidden_size)
        self.fc = nn.Linear(hidden_size, output_size)

    def forward(self, x):
        out, _ = self.lstm(x)
        out = out[:, -1, :]  # Take the output of the last time step
        out = self.batch_norm(out)
        out = self.fc(out)
        return out


y_train_tensor.detach().float()
y_test_tensor.detach().float()


# Model, loss function, and optimizer
input_size = X_train_reshaped.shape[2]
hidden_size = 64
output_size = 1
model = LSTMModel(input_size, hidden_size, output_size)
criterion = nn.BCEWithLogitsLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

# Training loop
epochs_lstm = 10

train_losses, train_accuracies, train_aucs = [], [], []
test_losses, test_accuracies, test_aucs = [], [], []

for epoch in range(epochs_lstm):
    # Train the model
    model.train()
    optimizer.zero_grad()
    outputs = model(X_train_reshaped)
    loss = criterion(outputs.squeeze(), y_train)
    loss.backward()
    optimizer.step()

    # Evaluate on training data
    model.eval()
    with torch.no_grad():
        train_preds = model(X_train_reshaped).squeeze()
        train_loss = criterion(train_preds, y_train)
        train_acc = accuracy_score(y_train.numpy(), (torch.sigmoid(train_preds) > 0.5).numpy())
        train_auc = roc_auc_score(y_train.numpy(), torch.sigmoid(train_preds).numpy())

        test_preds = model(X_test_reshaped).squeeze()
        test_loss = criterion(test_preds, y_test)
        test_acc = accuracy_score(y_test.numpy(), (torch.sigmoid(test_preds) > 0.5).numpy())
        test_auc = roc_auc_score(y_test.numpy(), torch.sigmoid(test_preds).numpy())

    # Save metrics
    train_losses.append(train_loss.item())
    train_accuracies.append(train_acc)
    train_aucs.append(train_auc)

    test_losses.append(test_loss.item())
    test_accuracies.append(test_acc)
    test_aucs.append(test_auc)

    print(f"Epoch [{epoch + 1}/{epochs_lstm}] - "
          f"Train Loss: {train_loss.item():.4f} - "
          f"Train Acc: {train_acc:.4f} - "
          f"Train AUC: {train_auc:.4f} - "
          f"Test Loss: {test_loss.item():.4f} - "
          f"Test Acc: {test_acc:.4f} - "
          f"Test AUC: {test_auc:.4f}")

model.eval()

# Plot ROC curve
with torch.no_grad():
    y_pred_probs = model(X_test_reshaped).squeeze()
    y_pred = (torch.sigmoid(y_pred_probs) > 0.5).numpy().astype(int)
    lstm_fpr, lstm_tpr, thresholds = roc_curve(y_test.numpy(), torch.sigmoid(test_preds).numpy())
    roc_auc = auc(lstm_fpr, lstm_tpr)


print(f'Test Accuracy: {test_acc*100:.4}%')

# Calculate additional metrics and display the classification report
print("Classification Report:")
class_names = ["Benign", "Malicious"]
print(classification_report(y_test, y_pred, target_names=class_names))

# Confusion Matrix
print("Confusion Matrix:")
conf_matrix = confusion_matrix(y_test, y_pred)
print(conf_matrix)

# Calculate Sensitivity and Specificity
sensitivity = conf_matrix[1, 1] / (conf_matrix[1, 1] + conf_matrix[1, 0])
specificity = conf_matrix[0, 0] / (conf_matrix[0, 0] + conf_matrix[0, 1])

print(f"Sensitivity: {sensitivity:.4f}")
print(f"Specificity: {specificity:.4f}")

plt.figure(figsize=(8, 6))
plt.plot(lstm_fpr, lstm_tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc='lower right')
plt.show()
