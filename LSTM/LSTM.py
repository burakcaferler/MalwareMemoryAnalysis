import sklearn.metrics
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np

df = pd.read_csv("Obfuscated-MalMem2022.csv", sep=',', encoding='utf-8')

for column in df.columns:
    if df[column].nunique() == 1:  # Find out whether the data is unique or not.
        print(f"All values {column} are identical")

# So we dont need printed values cuz they're already identical.
columns_to_drop = ['pslist.nprocs64bit', 'handles.nport', 'svcscan.interactive_process_services']
df.drop(columns=columns_to_drop, inplace=True)

# Forward filling missing values and dropping duplicates.
df.ffill()
df.drop_duplicates(inplace=True)


def find_category(column):
    if "-" in column:
        category = column.split("-")[0]
        return category
    else:
        return column


# Printing Categories
df["Category"] = df["Category"].apply(find_category)
print(df["Category"].value_counts())

# Data Type Conversion
df["Class"] = df["Class"].astype("category")

# Handling Categorical Data
df = pd.get_dummies(df, columns=["Class"], drop_first=True)

# Separate features and target
y = df["Class_Malware"]
X = df.drop(columns=["Category", "Class_Malware"])

# PCA Implementation
pca = PCA()
feature_scaled = StandardScaler().fit_transform(X)
feature_pca = pca.fit_transform(feature_scaled)
explained_variance_ratio = pca.explained_variance_ratio_
cumulative_variance_ratio = np.cumsum(explained_variance_ratio)

plt.plot(cumulative_variance_ratio)
plt.xlabel('Number of Principal Components')
plt.ylabel('Cumulative Explained Variance Ratio')
plt.grid(True)
plt.show()
# ------------------------------------------------------

from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA

lda = LDA(n_components=1)
X_lda = lda.fit_transform(feature_scaled, y)

from sklearn.manifold import TSNE

# Feature extraction using t-SNE
tsne = TSNE(n_components=2, perplexity=30, n_iter=300)
X_tsne = tsne.fit_transform(feature_scaled)

# Create subplots for side-by-side comparison
fig, axes = plt.subplots(1, 3, figsize=(15, 5))

# Plot PCA
axes[0].scatter(feature_pca[y == 0, 0], feature_pca[y == 0, 1], label="Benign", color="blue", alpha=0.5)
axes[0].scatter(feature_pca[y == 1, 0], feature_pca[y == 1, 1], label="Malicious", color="red", alpha=0.5)
axes[0].set_title("PCA")
axes[0].legend()

# Plot t-SNE
axes[1].scatter(X_tsne[y == 0, 0], X_tsne[y == 0, 1], label="Benign", color="blue", alpha=0.5)
axes[1].scatter(X_tsne[y == 1, 0], X_tsne[y == 1, 1], label="Malicious", color="red", alpha=0.5)
axes[1].set_title("t-SNE")
axes[1].legend()

# Plot LDA
axes[2].scatter(X_lda[y == 0, 0], X_lda[y == 0, 0], label="Benign", color="blue", alpha=0.5)
axes[2].scatter(X_lda[y == 1, 0], X_lda[y == 1, 0], label="Malicious", color="red", alpha=0.5)
axes[2].set_title("LDA")
axes[2].legend()

plt.show()


# -----------------------------------------------------------------------------------------
# Alt kısım implementasyon
# -----------------------------------------------------------------------------------------

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, roc_auc_score
import keras
from keras import layers

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.99, random_state=42)

X_train_reshaped = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))
X_test_reshaped = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))

model = keras.Sequential()
model.add(layers.LSTM(units=50, input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2])))
model.add(layers.BatchNormalization())
model.add(layers.Dense(1))
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
print(model.summary())

# Training and test parameters
epochs = 10

# Lists to store training and test performances
train_losses, train_accuracies, train_aucs = [], [], []
test_losses, test_accuracies, test_aucs = [], [], []

# Training loop
for epoch in range(epochs):
    # Train the model
    history = model.fit(X_train_reshaped, y_train, epochs=1, batch_size=32, validation_data=(X_test_reshaped, y_test),
                        verbose=0)

    # Save training results
    train_losses.append(history.history['loss'][0])
    train_accuracies.append(history.history['accuracy'][0])
    train_aucs.append(roc_auc_score(y_train, model.predict(X_train_reshaped)))

    # Save test results
    test_losses.append(history.history['val_loss'][0])
    test_accuracies.append(history.history['val_accuracy'][0])
    test_aucs.append(roc_auc_score(y_test, model.predict(X_test_reshaped)))

    # Calculate average loss and accuracies
    average_train_loss = sum(train_losses) / len(train_losses)
    average_test_loss = sum(test_losses) / len(test_losses)
    train_accuracy = sum(train_accuracies) / len(train_accuracies)
    test_accuracy = sum(test_accuracies) / len(test_accuracies)
    train_auc = sum(train_aucs) / len(train_aucs)
    test_auc = sum(test_aucs) / len(test_aucs)

    # Print the output
    print(f"Epoch [{epoch + 1}/{epochs}] - "
          f"Train Loss: {average_train_loss:.4f} - "
          f"Train Acc: {train_accuracy:.4f} - "
          f"Train AUC: {train_auc:.4f} - "
          f"Test Loss: {average_test_loss:.4f} - "
          f"Test Acc: {test_accuracy:.4f} - "
          f"Test AUC: {test_auc:.4f}")


from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

y_pred_probs = model.predict(X_test_reshaped)
y_pred = (y_pred_probs > 0.5).astype(int)  # Assuming binary classification, adjust threshold if needed

# Test Accuracy
print(f'Test Accuracy: {test_accuracy:.4f}/1.0000')

# Classification Report
print("Classification Report:")
class_names = ["Benign", "Malicious"]  # Adjust class names accordingly
print(classification_report(y_test, y_pred, target_names=class_names))

# Confusion Matrix
print("Confusion Matrix:")
conf_matrix = confusion_matrix(y_test, y_pred)
print(conf_matrix)

# Calculate Sensitivity and Specificity
sensitivity = conf_matrix[1, 1] / (conf_matrix[1, 1] + conf_matrix[1, 0])
specificity = conf_matrix[0, 0] / (conf_matrix[0, 0] + conf_matrix[0, 1])

print(f"Sensitivity: {sensitivity:.4f}")
print(f"Specificity: {specificity:.4f}")

# Curves

plt.plot(train_aucs)
plt.xlabel('AUC Curve')
plt.ylabel('True Positive Rate')
plt.xlabel('Epoch')
plt.grid(True)
plt.show()


from sklearn.metrics import roc_curve, auc

# Compute ROC curve for the test data
fpr, tpr, thresholds = roc_curve(y_test, y_pred_probs)
roc_auc = auc(fpr, tpr)

# Plot ROC curve
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc='lower right')
plt.show()